{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflowExample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongyyyyy/ColabDeepLearning/blob/master/MakingDeepLearningModelUsingNumpy/tensorflowExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Rn2-zcQ38S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def createRandomArray():\n",
        "    result = np.random.randint(0,2,3,dtype=int)\n",
        "    if(result[0]==0 and result[1]==0 and result[2] ==0):\n",
        "        output = 1\n",
        "    elif(result[0]==0 and result[1]==0 and result[2] == 1):\n",
        "        output = 2\n",
        "    elif(result[0]==0 and result[1]==1 and result[2] ==0):\n",
        "        output = 3\n",
        "    elif (result[0] == 0 and result[1] == 1 and result[2] == 1):\n",
        "        output = 4\n",
        "    elif (result[0] == 1 and result[1] == 0 and result[2] == 0):\n",
        "        output = 5\n",
        "    elif (result[0] == 1 and result[1] == 0 and result[2] == 1):\n",
        "        output = 6\n",
        "    elif (result[0] == 1 and result[1] == 1 and result[2] == 0):\n",
        "        output = 7\n",
        "    elif (result[0] == 1 and result[1] == 1 and result[2] == 1):\n",
        "        output = 8\n",
        "    noise = np.random.normal(0, 0.1, 3)\n",
        "    result = result - noise\n",
        "    return result , output\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    saveData = []\n",
        "    csvfile = open(\"TrainDataset.csv\",\"w\",newline=\"\")\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    for i in range(20000):\n",
        "        array,output = createRandomArray()\n",
        "        output = np.reshape(output,(1))\n",
        "        result = np.concatenate([array,output],axis=-1)\n",
        "        csvwriter.writerow(result)\n",
        "\n",
        "    csvfile.close()\n",
        "\n",
        "    csvfile = open(\"TestDataset.csv\", \"w\", newline=\"\")\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    for i in range(1000):\n",
        "        array,output = createRandomArray()\n",
        "        output = np.reshape(output,(1))\n",
        "        result = np.concatenate([array,output],axis=-1)\n",
        "        csvwriter.writerow(result)\n",
        "\n",
        "    csvfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrEEEVO-U_8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def createRandomArray():\n",
        "    result = np.random.randint(0,2,3,dtype=int)\n",
        "    if(result[0]==0 and result[1]==0 and result[2] ==0):\n",
        "        output = 1\n",
        "    elif(result[0]==0 and result[1]==0 and result[2] == 1):\n",
        "        output = 2\n",
        "    elif(result[0]==0 and result[1]==1 and result[2] ==0):\n",
        "        output = 3\n",
        "    elif (result[0] == 0 and result[1] == 1 and result[2] == 1):\n",
        "        output = 4\n",
        "    elif (result[0] == 1 and result[1] == 0 and result[2] == 0):\n",
        "        output = 5\n",
        "    elif (result[0] == 1 and result[1] == 0 and result[2] == 1):\n",
        "        output = 6\n",
        "    elif (result[0] == 1 and result[1] == 1 and result[2] == 0):\n",
        "        output = 7\n",
        "    elif (result[0] == 1 and result[1] == 1 and result[2] == 1):\n",
        "        output = 8\n",
        "    noise = np.random.normal(0, 0.3, 3)\n",
        "    result = result - noise\n",
        "    return result , output\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    saveData = []\n",
        "    csvfile = open(\"TrainDataset_03.csv\",\"w\",newline=\"\")\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    for i in range(20000):\n",
        "        array,output = createRandomArray()\n",
        "        output = np.reshape(output,(1))\n",
        "        result = np.concatenate([array,output],axis=-1)\n",
        "        csvwriter.writerow(result)\n",
        "\n",
        "    csvfile.close()\n",
        "\n",
        "    csvfile = open(\"TestDataset_03.csv\", \"w\", newline=\"\")\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    for i in range(1000):\n",
        "        array,output = createRandomArray()\n",
        "        output = np.reshape(output,(1))\n",
        "        result = np.concatenate([array,output],axis=-1)\n",
        "        csvwriter.writerow(result)\n",
        "\n",
        "    csvfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmj-FynsRHWZ",
        "colab_type": "code",
        "outputId": "72ca16c8-3a6d-459f-af5a-f4871738545a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t    TestDataset.csv\t TrainDataset.csv\n",
            "TestDataset_03.csv  TrainDataset_03.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGln1bDXRigN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def HandFunction(h,f):\n",
        "    result = np.array(np.zeros([len(h[0]), len(f[0])]))\n",
        "    h = h.sum(axis=0)\n",
        "    f = f.sum(axis=0)\n",
        "    for i in range(len(h)):\n",
        "        for j in range(len(f)):\n",
        "            result[i][j] = h[i] * f[j]\n",
        "    return result\n",
        "\n",
        "def HandFunction1(h,f):\n",
        "    result = np.array(np.zeros([len(f),len(f[0])]))\n",
        "    for i in range(len(f)): # 100\n",
        "        for j in range(len(f[0])): # 24\n",
        "            result[i][j] = h[j] * f[i][j] # 24 , (100,24) -> (100,24)\n",
        "    return result\n",
        "\n",
        "def HandFunction2(h,f):\n",
        "    result = np.array(np.zeros([len(h),len(f[0])]))\n",
        "    for i in range(len(f[0])): # 24\n",
        "        for j in range(len(h)): # 100\n",
        "            result[j][i] = h[j] * f[j][i] # (100) , (100,24) -> (100,24)\n",
        "    return result\n",
        "\n",
        "\n",
        "def ODivideFunction(h,f):\n",
        "    result = np.array(np.zeros([len(h), len(h[0])]))\n",
        "    for i in range(len(h)): # 100\n",
        "        for j in range(len(h[0])): # 8\n",
        "            result[i][j] = h[i][j] / f[i]\n",
        "    return result\n",
        "\n",
        "def MakeFristOne(h):\n",
        "    for i in range(len(h)):\n",
        "        h[i][0] = 1.\n",
        "    return h\n",
        "  \n",
        "def RetrunOneHot(input):\n",
        "        if input == 1:\n",
        "            return [1, 0, 0, 0, 0, 0, 0, 0]\n",
        "        elif input == 2:\n",
        "            return [0, 1, 0, 0, 0, 0, 0, 0]\n",
        "        elif input == 3:\n",
        "            return [0, 0, 1, 0, 0, 0, 0, 0]\n",
        "        elif input == 4:\n",
        "            return [0, 0, 0, 1, 0, 0, 0, 0]\n",
        "        elif input == 5:\n",
        "            return[0, 0, 0, 0, 1, 0, 0, 0]\n",
        "        elif input == 6:\n",
        "            return [0, 0, 0, 0, 0, 1, 0, 0]\n",
        "        elif input == 7:\n",
        "            return [0, 0, 0, 0, 0, 0, 1, 0]\n",
        "        elif input == 8:\n",
        "            return [0, 0, 0, 0, 0, 0, 0, 1]\n",
        "        else :\n",
        "          return [0, 0, 0, 0, 0, 0, 0, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvE4REIjRJrs",
        "colab_type": "code",
        "outputId": "72f25307-e13b-4fe8-91a1-e24d2103eac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "def V_Sigmoid():\n",
        "    sigmoid = np.vectorize(Sigmoid)\n",
        "    return sigmoid\n",
        "\n",
        "def V_ReLU():\n",
        "    relu = np.vectorize(ReLU)\n",
        "    return relu\n",
        "\n",
        "def Sigmoid(x):\n",
        "    try:\n",
        "        return 1 / (1 + exp(-x))\n",
        "    except OverflowError:\n",
        "        return 1.\n",
        "\n",
        "\n",
        "def ReLU(x):\n",
        "    return max(0, x)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    batch = 100\n",
        "    epoch = 20\n",
        "    startNumber = 0\n",
        "\n",
        "    data = np.loadtxt('TrainDataset.csv', delimiter=',', dtype=np.float32)\n",
        "    train_x_data = data[:, 0:-1]\n",
        "    bias = [[1.] * 1 for i in range(len(train_x_data))]\n",
        "    train_x_data_bias = np.concatenate((bias, train_x_data), axis=1)\n",
        "    train_y_data = data[:, [-1]]\n",
        "    train_y_data_onehot = []\n",
        "    print(\"데이터 총 개수 : \", len(train_y_data))\n",
        "    for i in range(len(train_y_data)):\n",
        "        if train_y_data[i] == 1:\n",
        "            train_y_data_onehot.append([1, 0, 0, 0, 0, 0, 0, 0])\n",
        "        elif train_y_data[i] == 2:\n",
        "            train_y_data_onehot.append([0, 1, 0, 0, 0, 0, 0, 0])\n",
        "        elif train_y_data[i] == 3:\n",
        "            train_y_data_onehot.append([0, 0, 1, 0, 0, 0, 0, 0])\n",
        "        elif train_y_data[i] == 4:\n",
        "            train_y_data_onehot.append([0, 0, 0, 1, 0, 0, 0, 0])\n",
        "        elif train_y_data[i] == 5:\n",
        "            train_y_data_onehot.append([0, 0, 0, 0, 1, 0, 0, 0])\n",
        "        elif train_y_data[i] == 6:\n",
        "            train_y_data_onehot.append([0, 0, 0, 0, 0, 1, 0, 0])\n",
        "        elif train_y_data[i] == 7:\n",
        "            train_y_data_onehot.append([0, 0, 0, 0, 0, 0, 1, 0])\n",
        "        elif train_y_data[i] == 8:\n",
        "            train_y_data_onehot.append([0, 0, 0, 0, 0, 0, 0, 1])\n",
        "    W = np.random.rand(4,8)\n",
        "\n",
        "    def forward(x, y):\n",
        "\n",
        "        z1 = np.dot(x,W)\n",
        "        o = ODivideFunction(np.exp(z1), np.sum(np.exp(z1), axis=1))\n",
        "        e = np.mean(-np.sum(y * np.log(o), axis=1))\n",
        "\n",
        "        return e, o, z1\n",
        "\n",
        "\n",
        "    def backward(x, y, W, input_data):\n",
        "        local_param = (x-y)\n",
        "        result = HandFunction(input_data,local_param)\n",
        "        delta_o = (-learning_rate)*result\n",
        "        NW = W + delta_o\n",
        "\n",
        "        return NW\n",
        "\n",
        "    def Accuracy(x,y,batch):\n",
        "        z1 = np.dot(x,W)\n",
        "        o = ODivideFunction(np.exp(z1), np.sum(np.exp(z1), axis=1))\n",
        "        accuracy = 0.\n",
        "        for i in range(batch):\n",
        "            if (np.argmax(o[i])==np.argmax(y[i])):\n",
        "                accuracy = accuracy + 1.\n",
        "        return accuracy/batch * 100\n",
        "\n",
        "    maxBatch = int(len(train_x_data_bias) / batch)\n",
        "    print(\"batch size   = \", batch)\n",
        "    print(\"batch Number = \", maxBatch)\n",
        "    count = 0\n",
        "    for i in range(epoch):  # 10 번 반복\n",
        "        Eavg = 0.\n",
        "        startNumber = 0\n",
        "        for j in range(maxBatch):  # 200번 반복\n",
        "            x_batch = train_x_data_bias[startNumber:startNumber + 100]\n",
        "            y_batch = train_y_data_onehot[startNumber:startNumber + 100]\n",
        "            if (len(x_batch) != 0):\n",
        "                Eav, error, z1 = forward(x_batch, y_batch)\n",
        "                W = backward(error, y_batch, W,x_batch)\n",
        "                # print(W1)\n",
        "                Eavg = Eavg + Eav\n",
        "                startNumber = startNumber + 100\n",
        "        print(\"Epoch \",i+1,\"Eavg : \",Eavg/maxBatch)\n",
        "\n",
        "    test = np.loadtxt('TestDataset.csv', delimiter=',', dtype=np.float32)\n",
        "    test_x_data = data[:, 0:-1]\n",
        "    test_bias = [[1.] * 1 for i in range(len(test_x_data))]\n",
        "    test_x_data_bias = np.concatenate((test_bias, train_x_data), axis=1)\n",
        "    test_y_data = data[:, [-1]]\n",
        "    test_y_data_onehot = []\n",
        "    for i in range(len(test_y_data)):\n",
        "        test_y_data_onehot.append(RetrunOneHot(test_y_data[i]))\n",
        "\n",
        "    Eavg = 0.\n",
        "    startNumber = 0\n",
        "    Aavg = 0.\n",
        "    for i in range(len(test_x_data_bias)): # 200번 반복\n",
        "        x_batch = test_x_data_bias[startNumber:startNumber+batch]\n",
        "        y_batch = test_y_data_onehot[startNumber:startNumber+batch]\n",
        "        if(len(x_batch)!= 0):\n",
        "            accuracy = Accuracy(x_batch,y_batch,batch)\n",
        "            Aavg = Aavg + accuracy\n",
        "            startNumber = startNumber + 100\n",
        "    print(\"Aavg : {:.4f}%\".format((Aavg/len(test_x_data_bias))*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 총 개수 :  20000\n",
            "batch size   =  100\n",
            "batch Number =  200\n",
            "Epoch  1 Eavg :  1.9427297312442096\n",
            "Epoch  2 Eavg :  1.1478884706627688\n",
            "Epoch  3 Eavg :  0.8201569427165246\n",
            "Epoch  4 Eavg :  0.6487832306818427\n",
            "Epoch  5 Eavg :  0.5399679957739402\n",
            "Epoch  6 Eavg :  0.45849186505938627\n",
            "Epoch  7 Eavg :  0.40585751013862753\n",
            "Epoch  8 Eavg :  0.3669788907374947\n",
            "Epoch  9 Eavg :  0.32605677813551365\n",
            "Epoch  10 Eavg :  0.2850789975905618\n",
            "Epoch  11 Eavg :  0.24535929164275877\n",
            "Epoch  12 Eavg :  0.2093172536354702\n",
            "Epoch  13 Eavg :  0.18094530624915095\n",
            "Epoch  14 Eavg :  0.1606168188588763\n",
            "Epoch  15 Eavg :  0.14633621978188\n",
            "Epoch  16 Eavg :  0.13538347732034495\n",
            "Epoch  17 Eavg :  0.12652569832717434\n",
            "Epoch  18 Eavg :  0.11911511943172515\n",
            "Epoch  19 Eavg :  0.11275976608919464\n",
            "Epoch  20 Eavg :  0.1072040396938015\n",
            "Aavg : 100.0000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlrJ9ph3S4SG",
        "colab_type": "code",
        "outputId": "ce97c874-b5d7-469a-bedf-d904e8690674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "\n",
        "def V_Sigmoid():\n",
        "    sigmoid = np.vectorize(Sigmoid)\n",
        "    return sigmoid\n",
        "\n",
        "def V_ReLU():\n",
        "    relu = np.vectorize(ReLU)\n",
        "    return relu\n",
        "\n",
        "def Sigmoid(x):\n",
        "    try:\n",
        "        return 1 / (1 + exp(-x))\n",
        "    except OverflowError:\n",
        "        return 1.\n",
        "\n",
        "\n",
        "def ReLU(x):\n",
        "    return max(0, x)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    batch = 100\n",
        "    epoch = 10\n",
        "    startNumber = 0\n",
        "\n",
        "    # 데이터 가져오는 작업\n",
        "    data = np.loadtxt('TrainDataset.csv', delimiter=',', dtype=np.float32) # 해당 txt파일에서 데이터를 가져옴\n",
        "    train_x_data = data[:, 0:-1] # 열에서 가장 마지막 값을 제외한 모든 값\n",
        "    bias = [[1.] * 1 for i in range(len(train_x_data))] \n",
        "    train_x_data_bias = np.concatenate((bias, train_x_data), axis=1) # bias값을 가장 맨 앞 (0)위치에 이어붙인다\n",
        "    train_y_data = data[:, [-1]] # 마지막 값 ( classes )을 y data ( label )로 저장\n",
        "    train_y_data_onehot = [] # y_data값은 1~8사이의 값이므로 이를 one_hot인코딩을 하여 값을 저장\n",
        "    print(\"데이터 총 개수 : \", len(train_y_data)) \n",
        "    for i in range(len(train_y_data)):\n",
        "            train_y_data_onehot.append(RetrunOneHot(train_y_data[i]))\n",
        "    W1 = np.random.rand(4,24) # input과 1번 layer의 연결강도를 의미하는 W1 가중치\n",
        "    W2 = np.random.rand(24,8) # 1번 layer와 출력 layer의 연결강도를 의미하는 W2 가중치\n",
        "\n",
        "\n",
        "    def forward(x, y):\n",
        "        z1 = np.dot(x,W1)\n",
        "        h1 = MakeFristOne(z1)\n",
        "\n",
        "        z2 = np.dot(h1,W2)\n",
        "        o = ODivideFunction(np.exp(z2), np.sum(np.exp(z2),axis=1))\n",
        "        e = np.mean(-np.sum(y*np.log(o),axis=1))\n",
        "\n",
        "\n",
        "        return e, o, h1\n",
        "\n",
        "\n",
        "    def backward(x, y, W1, W2, input_data,h1): # x = O(n) , y = label , W = Weight\n",
        "        local_param2 = (x - y)\n",
        "        result = HandFunction(h1, local_param2)\n",
        "        delta_o = (-learning_rate) * result\n",
        "        NW2 = W2 + delta_o\n",
        "\n",
        "        local_param1 = np.dot(local_param2,np.transpose(W2))\n",
        "        result = HandFunction(input_data, local_param1)\n",
        "        delta_h1 = (-learning_rate) * result\n",
        "        NW1 = W1 + delta_h1\n",
        "        \n",
        "        return NW1, NW2\n",
        "\n",
        "    def Accuracy(x, y, batch):\n",
        "        z1 = np.dot(x,W1)\n",
        "        h1 = MakeFristOne(z1)\n",
        "\n",
        "        z2 = np.dot(h1,W2)\n",
        "        o = ODivideFunction(np.exp(z2), np.sum(np.exp(z2),axis=1))\n",
        "        accuracy = 0.\n",
        "        for i in range(batch):\n",
        "            if (np.argmax(o[i])==np.argmax(y[i])):\n",
        "                accuracy = accuracy + 1.\n",
        "                \n",
        "        return float(accuracy)/batch * 100, o\n",
        "\n",
        "    maxBatch = int(len(train_x_data_bias) / batch)\n",
        "    print(\"batch size   = \", batch)\n",
        "    print(\"batch Number = \", maxBatch)\n",
        "    count = 0\n",
        "    for i in range(epoch):  # 10 번 반복\n",
        "        Eavg = 0.\n",
        "        startNumber = 0\n",
        "        for j in range(maxBatch):  # 200번 반복\n",
        "            x_batch = train_x_data_bias[startNumber:startNumber + 100]\n",
        "            y_batch = train_y_data_onehot[startNumber:startNumber + 100]\n",
        "            if (len(x_batch) != 0):\n",
        "                Eav, error, h1 = forward(x_batch, y_batch)\n",
        "                W1,W2 = backward(error, y_batch, W1,W2,x_batch,h1 )\n",
        "                # print(W1)\n",
        "                Eavg = Eavg + Eav\n",
        "                startNumber = startNumber + 100\n",
        "        print(\"Epoch \",i+1,\"Eavg : \",Eavg/maxBatch)\n",
        "\n",
        "    test = np.loadtxt('TestDataset.csv', delimiter=',', dtype=np.float32)\n",
        "    test_x_data = data[:, 0:-1]\n",
        "    test_bias = [[1.] * 1 for i in range(len(test_x_data))]\n",
        "    test_x_data_bias = np.concatenate((test_bias, train_x_data), axis=1)\n",
        "    test_y_data = data[:, [-1]]\n",
        "    test_y_data_onehot = []\n",
        "    for i in range(len(test_y_data)):\n",
        "        test_y_data_onehot.append(RetrunOneHot(test_y_data[i]))\n",
        "\n",
        "    Eavg = 0.\n",
        "    startNumber = 0\n",
        "    Aavg = 0.\n",
        "    a = 0\n",
        "    for i in range(len(test_x_data_bias)): # 200번 반복\n",
        "        x_batch = test_x_data_bias[startNumber:startNumber+batch]\n",
        "        y_batch = test_y_data_onehot[startNumber:startNumber+batch]\n",
        "        if(len(x_batch)!= 0):\n",
        "            accuracy, pred = Accuracy(x_batch,y_batch,batch)\n",
        "            if( a == 0):\n",
        "                print(\"Label : \", np.argmax(y_batch, axis=1))\n",
        "                print(\"pred : \",np.argmax(pred,axis=1))\n",
        "                a += 1\n",
        "            Aavg = Aavg + accuracy\n",
        "            startNumber = startNumber + 100\n",
        "    print(\"Aavg : {}%\".format((Aavg/len(test_x_data_bias))*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 총 개수 :  20000\n",
            "batch size   =  100\n",
            "batch Number =  200\n",
            "Epoch  1 Eavg :  1.9682248623906162\n",
            "Epoch  2 Eavg :  1.5235499577187965\n",
            "Epoch  3 Eavg :  1.2503493961525591\n",
            "Epoch  4 Eavg :  1.0128076655413087\n",
            "Epoch  5 Eavg :  0.8078905472675921\n",
            "Epoch  6 Eavg :  0.6395129041272457\n",
            "Epoch  7 Eavg :  0.5073271058685926\n",
            "Epoch  8 Eavg :  0.4064794008198491\n",
            "Epoch  9 Eavg :  0.3303766311641861\n",
            "Epoch  10 Eavg :  0.27283334984482704\n",
            "Label :  [6 5 3 3 1 7 0 0 0 4 7 7 5 4 5 4 5 0 7 7 2 6 4 1 1 2 0 0 6 4 7 6 3 1 4 4 6\n",
            " 2 1 7 7 0 6 3 4 2 6 2 0 0 5 3 0 4 7 5 5 3 6 2 4 2 7 5 2 7 0 1 0 7 2 1 5 5\n",
            " 6 0 3 4 3 5 0 2 1 4 7 1 1 1 4 7 3 6 0 1 5 4 3 5 1 0]\n",
            "pred :  [6 5 3 3 1 7 0 0 0 4 7 7 5 4 5 4 5 0 7 7 2 6 4 1 1 2 0 0 6 4 7 6 3 1 4 4 6\n",
            " 2 1 7 7 0 6 3 4 2 6 2 0 0 5 3 0 4 7 5 5 3 6 2 4 2 7 5 2 7 0 1 0 7 2 1 5 5\n",
            " 6 0 3 4 3 5 0 2 1 4 7 1 1 1 4 7 3 6 0 1 5 4 3 5 1 0]\n",
            "Aavg : 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRfpuPMSqb8-",
        "colab_type": "code",
        "outputId": "8dd937e1-3a9c-4b8c-9b7a-15a557901811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "\n",
        "learning_rate = 0.0001 # learning rate\n",
        "\n",
        "plt_Eavg = [] \n",
        "plt_Eavg2 = []\n",
        "\n",
        "class Model:\n",
        "    def __init__(self, batch): # 클래스 생성시 초기화\n",
        "        self.W1 = np.random.rand(4,24) \n",
        "        self.W2 = np.random.rand(24,8)\n",
        "        self.h1 = np.random.rand(batch, 24)\n",
        "\n",
        "    def forward(self, input_data, input_truth): # 전 방향 \n",
        "        z1 = np.dot(input_data, self.W1)\n",
        "        self.h1 = MakeFristOne(z1)\n",
        "\n",
        "        z2 = np.dot(self.h1, self.W2)\n",
        "        o = ODivideFunction(np.exp(z2), np.sum(np.exp(z2),axis=1))\n",
        "        e = np.mean(-np.sum(input_truth*np.log(o),axis=1))\n",
        "\n",
        "        return e, o\n",
        "\n",
        "    def backward(self, pred, truth, input_data): # x = O(n) , y = label , W = Weight / backpropagation\n",
        "        local_param2 = (pred - truth) # 국부적 기울기\n",
        "        result = np.dot(np.transpose(self.h1), local_param2) # 국부적 기울기 * h1\n",
        "        delta_o = (-learning_rate) * result # W2 변화량\n",
        "        nw2 = self.W2 + delta_o # 다음 W2 = 현재 W2 + W2의 변화량\n",
        "\n",
        "        local_param1 = np.dot(local_param2, np.transpose(self.W2)) # 국부적 기울기\n",
        "        result = HandFunction(input_data, local_param1) # 국부적 기울기 * 입력값\n",
        "        delta_h1 = (-learning_rate) * result # W1 변화량\n",
        "        nw1 = self.W1 + delta_h1 # 다음 W1 = 현재 W1 + W1의 변화량\n",
        "\n",
        "        self.W1 = nw1\n",
        "        self.W2 = nw2\n",
        "\n",
        "    def Accuracy(self, input_data, input_truth, batch): # 정확도 확인을 위한 함수\n",
        "        z1 = np.dot(input_data, self.W1)\n",
        "        h1 = MakeFristOne(z1)\n",
        "\n",
        "        z2 = np.dot(h1, self.W2)\n",
        "        o = ODivideFunction(np.exp(z2), np.sum(np.exp(z2), axis=1))\n",
        "        accuracy = 0.\n",
        "        for i in range(batch):\n",
        "            if np.argmax(o[i]) == np.argmax(input_truth[i]): # truth와 pred이 일치할 경우\n",
        "                accuracy = accuracy + 1.\n",
        "\n",
        "        return accuracy/batch * 100, o\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    batch = 100 # mini-batch size 한번에 100개의 이미지를 학습한 후 update\n",
        "    epoch = 10 # 전체의 이미지 수를 10번 만큼 반복 학습\n",
        "    startNumber = 0\n",
        "\n",
        "    data = np.loadtxt('TrainDataset.csv', delimiter=',', dtype=np.float32) # 데이터 가져오기 \n",
        "    train_x_data = data[:, 0:-1] # 맨 마지막 전까지의 데이터를 X 데이터 ( 입력 데이터 )\n",
        "    bias = [[1.] * 1 for i in range(len(train_x_data))] # 입력 데이터에도 bias값 (+1)을 추가하기 위한 리스트 선언\n",
        "    train_x_data_bias = np.concatenate((bias, train_x_data), axis=1) # 입력 데이터에 bias값 추가\n",
        "    train_y_data = data[:, [-1]] # 마지막 데이터를 y 데이터 ( 정답 )\n",
        "    train_y_data_onehot = [] # one_hot encoding을 통하여 데이터 변형\n",
        "\n",
        "    data = np.loadtxt('TrainDataset_03.csv', delimiter=',', dtype=np.float32)\n",
        "    train_x_data_03 = data[:, 0:-1]\n",
        "    bias = [[1.] * 1 for i in range(len(train_x_data_03))]\n",
        "    train_x_data_03_bias = np.concatenate((bias, train_x_data_03), axis=1)\n",
        "    train_y_data_03 = data[:, [-1]]\n",
        "    train_y_data_03_onehot = []\n",
        "\n",
        "\n",
        "    print(\"데이터 총 개수 : \", len(train_y_data_03))\n",
        "    for i in range(len(train_y_data)):\n",
        "        train_y_data_onehot.append(RetrunOneHot(train_y_data[i]))\n",
        "    for i in range(len(train_y_data_03)):\n",
        "        train_y_data_03_onehot.append(RetrunOneHot(train_y_data_03[i]))\n",
        "\n",
        "    maxBatch = int(len(train_x_data_03_bias) / batch)\n",
        "\n",
        "    m1 = Model(batch) # 클래스 생성\n",
        "    m2 = Model(batch) # 클래스 생성\n",
        "\n",
        "    print(\"batch size   = \", batch)\n",
        "    print(\"batch Number = \", maxBatch)\n",
        "    count = 0\n",
        "    for i in range(epoch):  # 10 번 반복\n",
        "        Eavg = 0.\n",
        "        Eavg2 = 0.\n",
        "        startNumber = 0\n",
        "        for j in range(maxBatch):  # 200번 반복 = 20000 / batch(100)\n",
        "            x_batch = train_x_data_bias[startNumber:startNumber + 100]\n",
        "            y_batch = train_y_data_onehot[startNumber:startNumber + 100]\n",
        "            x_batch2 = train_x_data_03_bias[startNumber:startNumber + 100]\n",
        "            y_batch2 = train_y_data_03_onehot[startNumber:startNumber + 100]\n",
        "            if (len(x_batch) != 0):\n",
        "                Eav, pred = m1.forward(x_batch, y_batch) # forward\n",
        "                m1.backward(pred, y_batch, x_batch) # backward\n",
        "\n",
        "                Eav2, pred2 = m2.forward(x_batch2, y_batch2)\n",
        "                m2.backward(pred2, y_batch2, x_batch2)\n",
        "\n",
        "                Eavg = Eavg + Eav\n",
        "                Eavg2 = Eavg2 + Eav2\n",
        "                startNumber = startNumber + 100\n",
        "        print(\"Epoch \", i + 1, \"Eavg : \", Eavg/maxBatch)\n",
        "        plt_Eavg.append(Eavg/maxBatch) \n",
        "        print(\"Epoch \", i + 1, \"Eavg2 : \", Eavg2 / maxBatch)\n",
        "        plt_Eavg2.append(Eavg2/maxBatch)\n",
        "    \n",
        "    test = np.loadtxt('TestDataset.csv', delimiter=',', dtype=np.float32)\n",
        "    test_x_data = test[:, 0:-1]\n",
        "    test_bias = [[1.] * 1 for i in range(len(test_x_data))]\n",
        "    test_x_data_bias = np.concatenate((test_bias, test_x_data), axis=1)\n",
        "    test_y_data = test[:, [-1]]\n",
        "    test_y_data_onehot = []\n",
        "    for i in range(len(test_y_data)):\n",
        "        test_y_data_onehot.append(RetrunOneHot(test_y_data[i]))\n",
        "\n",
        "    test = np.loadtxt('TestDataset_03.csv', delimiter=',', dtype=np.float32)\n",
        "    test_x_data_03 = test[:, 0:-1]\n",
        "    test_x_data_03_bias = np.concatenate((test_bias, test_x_data_03), axis=1)\n",
        "    test_y_data_03 = test[:, [-1]]\n",
        "    test_y_data_03_onehot = []\n",
        "\n",
        "    for i in range(len(test_y_data_03)):\n",
        "        test_y_data_03_onehot.append(RetrunOneHot(test_y_data_03[i]))\n",
        "\n",
        "    startNumber = 0\n",
        "    Aavg = 0.\n",
        "    Aavg2 = 0.\n",
        "    a = 0\n",
        "    for i in range(len(test_x_data_bias)): # 200번 반복\n",
        "        x_batch = test_x_data_bias[startNumber:startNumber+batch]\n",
        "        y_batch = test_y_data_onehot[startNumber:startNumber+batch]\n",
        "        x_batch2 = test_x_data_03_bias[startNumber:startNumber+batch]\n",
        "        y_batch2 = test_y_data_03_onehot[startNumber:startNumber+batch]\n",
        "        if(len(x_batch)!= 0):\n",
        "            accuracy, pred = m1.Accuracy(x_batch, y_batch, batch)\n",
        "            accuracy2, pred2 = m2.Accuracy(x_batch2, y_batch2, batch)\n",
        "            if(a == 0):\n",
        "                print(\"Label : \", np.argmax(y_batch, axis=1))\n",
        "                print(\"pred : \", np.argmax(pred, axis=1))\n",
        "                a += 1\n",
        "            Aavg = Aavg + accuracy\n",
        "            Aavg2 = Aavg2 + accuracy2\n",
        "            startNumber = startNumber + 100\n",
        "\n",
        "    print(\"Aavg : {}%\".format((float(Aavg)/len(test_x_data_bias))*100))\n",
        "\n",
        "    print(\"Aavg2 : {:.4f}%\".format((float(Aavg2) / len(test_x_data_03_bias))*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 총 개수 :  20000\n",
            "batch size   =  100\n",
            "batch Number =  200\n",
            "Epoch  1 Eavg :  1.9132085987785168\n",
            "Epoch  1 Eavg2 :  2.016058722780397\n",
            "Epoch  2 Eavg :  1.4258134454612665\n",
            "Epoch  2 Eavg2 :  1.458683615679732\n",
            "Epoch  3 Eavg :  1.080525890011097\n",
            "Epoch  3 Eavg2 :  1.1447244671054322\n",
            "Epoch  4 Eavg :  0.8121696910014606\n",
            "Epoch  4 Eavg2 :  0.9400854617884339\n",
            "Epoch  5 Eavg :  0.6109155234282934\n",
            "Epoch  5 Eavg2 :  0.8028112942586452\n",
            "Epoch  6 Eavg :  0.4660531673170476\n",
            "Epoch  6 Eavg2 :  0.7082725499719669\n",
            "Epoch  7 Eavg :  0.36346287469265626\n",
            "Epoch  7 Eavg2 :  0.641116099964532\n",
            "Epoch  8 Eavg :  0.29039511034207505\n",
            "Epoch  8 Eavg2 :  0.5919061057383048\n",
            "Epoch  9 Eavg :  0.237430325935554\n",
            "Epoch  9 Eavg2 :  0.5548166641587265\n",
            "Epoch  10 Eavg :  0.1981797823194908\n",
            "Epoch  10 Eavg2 :  0.5261715814239927\n",
            "Label :  [6 7 4 7 7 2 4 0 3 7 2 4 1 0 3 6 7 5 2 6 0 0 2 3 0 1 6 3 0 0 2 2 2 4 2 1 6\n",
            " 0 6 4 2 3 6 0 4 0 5 4 7 5 2 7 0 5 0 2 7 3 4 2 5 5 7 5 7 0 3 1 7 3 7 2 0 4\n",
            " 0 3 4 2 4 7 2 1 2 7 5 6 0 6 3 2 2 6 3 7 6 2 7 1 4 6]\n",
            "pred :  [6 7 4 7 7 2 4 0 3 7 2 4 1 0 3 6 7 5 2 6 0 0 2 3 0 1 6 3 0 0 2 2 2 4 2 1 6\n",
            " 0 6 4 2 3 6 0 4 0 5 4 7 5 2 7 0 5 0 2 7 3 4 2 5 5 7 5 7 0 3 1 7 3 7 2 0 4\n",
            " 0 3 4 2 4 7 2 1 2 7 5 6 0 6 3 2 2 6 3 7 6 2 7 1 4 6]\n",
            "Aavg : 100.0%\n",
            "Aavg2 : 85.5000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqU-lCLHU1mm",
        "colab_type": "code",
        "outputId": "345b198a-b5e5-4d21-8fe0-a041d0eea44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "x = range(0,10)\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Eavg')\n",
        "\n",
        "plt.title('One Hidden Layer Model')\n",
        "plt.plot(x,plt_Eavg,label= \"Noise=0.1\")\n",
        "plt.plot(x,plt_Eavg2,label = 'Noise=0.3')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niwWGMcYYv1hgGGOM8cv/AyEZxeCZdEF7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}